const std = @import("std");
const zsts = @import("zsts");
const time = std.time;
const print = std.debug.print;

/// Performance Benchmarking Suite for Statistical Tests
/// æ€§èƒ½åŸºå‡†æµ‹è¯•å¥—ä»¶
const BenchmarkConfig = struct {
    iterations: u32 = 100,
    data_sizes: []const usize = &[_]usize{ 1000, 10000, 100000, 1000000 },
    test_types: []const TestType = &[_]TestType{ .frequency, .runs, .poker, .dft, .rank },
};

const TestType = enum {
    frequency,
    runs,
    poker,
    dft,
    rank,
    block_frequency,
    autocorrelation,
};

const BenchmarkResult = struct {
    test_name: []const u8,
    data_size: usize,
    avg_time_ns: u64,
    min_time_ns: u64,
    max_time_ns: u64,
    throughput_mbps: f64, // Megabits per second
};

fn generateTestData(allocator: std.mem.Allocator, size: usize, seed: u64) ![]u8 {
    var rnd = std.Random.DefaultPrng.init(seed);
    var random = rnd.random();

    var data = try allocator.alloc(u8, size);
    for (0..size) |i| {
        data[i] = if (random.boolean()) '1' else '0';
    }
    return data;
}

fn benchmarkFrequencyTest(allocator: std.mem.Allocator, data: []const u8, iterations: u32) !BenchmarkResult {
    var min_time: u64 = std.math.maxInt(u64);
    var max_time: u64 = 0;
    var total_time: u64 = 0;

    for (0..iterations) |_| {
        const bits = zsts.io.BitInputStream.fromAscii(allocator, data);
        defer bits.close();

        const param = zsts.detect.DetectParam{
            .type = zsts.detect.DetectType.Frequency,
            .n = data.len,
            .extra = null,
        };

        const stat = try zsts.frequency.frequencyDetectStatDetect(allocator, param);
        defer stat.destroy();

        const start = time.nanoTimestamp();
        stat.init(&param);
        _ = stat.iterate(&bits);
        const end = time.nanoTimestamp();

        const duration = @as(u64, @intCast(end - start));
        total_time += duration;
        min_time = @min(min_time, duration);
        max_time = @max(max_time, duration);
    }

    const avg_time = total_time / iterations;
    const throughput = (@as(f64, @floatFromInt(data.len)) / 1_000_000.0) / (@as(f64, @floatFromInt(avg_time)) / 1_000_000_000.0);

    return BenchmarkResult{
        .test_name = "Frequency",
        .data_size = data.len,
        .avg_time_ns = avg_time,
        .min_time_ns = min_time,
        .max_time_ns = max_time,
        .throughput_mbps = throughput,
    };
}

fn benchmarkRunsTest(allocator: std.mem.Allocator, data: []const u8, iterations: u32) !BenchmarkResult {
    var min_time: u64 = std.math.maxInt(u64);
    var max_time: u64 = 0;
    var total_time: u64 = 0;

    for (0..iterations) |_| {
        const bits = zsts.io.BitInputStream.fromAscii(allocator, data);
        defer bits.close();

        const param = zsts.detect.DetectParam{
            .type = zsts.detect.DetectType.Runs,
            .n = data.len,
            .extra = null,
        };

        const stat = try zsts.runs.runsDetectStatDetect(allocator, param);
        defer stat.destroy();

        const start = time.nanoTimestamp();
        stat.init(&param);
        _ = stat.iterate(&bits);
        const end = time.nanoTimestamp();

        const duration = @as(u64, @intCast(end - start));
        total_time += duration;
        min_time = @min(min_time, duration);
        max_time = @max(max_time, duration);
    }

    const avg_time = total_time / iterations;
    const throughput = (@as(f64, @floatFromInt(data.len)) / 1_000_000.0) / (@as(f64, @floatFromInt(avg_time)) / 1_000_000_000.0);

    return BenchmarkResult{
        .test_name = "Runs",
        .data_size = data.len,
        .avg_time_ns = avg_time,
        .min_time_ns = min_time,
        .max_time_ns = max_time,
        .throughput_mbps = throughput,
    };
}

fn benchmarkDftTest(allocator: std.mem.Allocator, data: []const u8, iterations: u32) !BenchmarkResult {
    var min_time: u64 = std.math.maxInt(u64);
    var max_time: u64 = 0;
    var total_time: u64 = 0;

    for (0..iterations) |_| {
        const bits = zsts.io.BitInputStream.fromAscii(allocator, data);
        defer bits.close();

        const param = zsts.detect.DetectParam{
            .type = zsts.detect.DetectType.Dft,
            .n = data.len,
            .extra = null,
        };

        const stat = try zsts.dft.dftDetectStatDetect(allocator, param);
        defer stat.destroy();

        const start = time.nanoTimestamp();
        stat.init(&param);
        _ = stat.iterate(&bits);
        const end = time.nanoTimestamp();

        const duration = @as(u64, @intCast(end - start));
        total_time += duration;
        min_time = @min(min_time, duration);
        max_time = @max(max_time, duration);
    }

    const avg_time = total_time / iterations;
    const throughput = (@as(f64, @floatFromInt(data.len)) / 1_000_000.0) / (@as(f64, @floatFromInt(avg_time)) / 1_000_000_000.0);

    return BenchmarkResult{
        .test_name = "DFT",
        .data_size = data.len,
        .avg_time_ns = avg_time,
        .min_time_ns = min_time,
        .max_time_ns = max_time,
        .throughput_mbps = throughput,
    };
}

fn benchmarkRankTest(allocator: std.mem.Allocator, data: []const u8, iterations: u32) !BenchmarkResult {
    // Rank test needs sufficient data (32x32 matrices)
    if (data.len < 32 * 32) {
        return BenchmarkResult{
            .test_name = "Rank",
            .data_size = data.len,
            .avg_time_ns = 0,
            .min_time_ns = 0,
            .max_time_ns = 0,
            .throughput_mbps = 0.0,
        };
    }

    var min_time: u64 = std.math.maxInt(u64);
    var max_time: u64 = 0;
    var total_time: u64 = 0;

    for (0..iterations) |_| {
        const bits = zsts.io.BitInputStream.fromAscii(allocator, data);
        defer bits.close();

        const param = zsts.detect.DetectParam{
            .type = zsts.detect.DetectType.Rank,
            .n = data.len,
            .extra = null,
        };

        const stat = try zsts.rank.rankDetectStatDetect(allocator, param);
        defer stat.destroy();

        const start = time.nanoTimestamp();
        stat.init(&param);
        _ = stat.iterate(&bits);
        const end = time.nanoTimestamp();

        const duration = @as(u64, @intCast(end - start));
        total_time += duration;
        min_time = @min(min_time, duration);
        max_time = @max(max_time, duration);
    }

    const avg_time = total_time / iterations;
    const throughput = (@as(f64, @floatFromInt(data.len)) / 1_000_000.0) / (@as(f64, @floatFromInt(avg_time)) / 1_000_000_000.0);

    return BenchmarkResult{
        .test_name = "Rank",
        .data_size = data.len,
        .avg_time_ns = avg_time,
        .min_time_ns = min_time,
        .max_time_ns = max_time,
        .throughput_mbps = throughput,
    };
}

fn formatTime(ns: u64) void {
    if (ns < 1000) {
        print("{d:>8}ns", .{ns});
    } else if (ns < 1_000_000) {
        print("{d:>8.2}Î¼s", .{@as(f64, @floatFromInt(ns)) / 1000.0});
    } else if (ns < 1_000_000_000) {
        print("{d:>8.2}ms", .{@as(f64, @floatFromInt(ns)) / 1_000_000.0});
    } else {
        print("{d:>8.2}s ", .{@as(f64, @floatFromInt(ns)) / 1_000_000_000.0});
    }
}

fn printBenchmarkResult(result: BenchmarkResult) void {
    print("â”‚ {s:<12} â”‚ {d:>8} â”‚ ", .{ result.test_name, result.data_size });
    formatTime(result.avg_time_ns);
    print(" â”‚ ", .{});
    formatTime(result.min_time_ns);
    print(" â”‚ ", .{});
    formatTime(result.max_time_ns);
    print(" â”‚ {d:>8.2} MB/s â”‚\n", .{result.throughput_mbps});
}

pub fn runPerformanceBenchmark(allocator: std.mem.Allocator) !void {
    const config = BenchmarkConfig{};

    print("\nðŸ”¥ STS-Zig Performance Benchmark Suite\n", .{});
    print("=====================================\n\n", .{});

    print("Configuration:\n", .{});
    print("- Iterations per test: {d}\n", .{config.iterations});
    print("- Test data sizes: ", .{});
    for (config.data_sizes) |size| {
        print("{d} ", .{size});
    }
    print("bits\n", .{});
    print("- Compiler optimizations: ReleaseFast equivalent\n\n", .{});

    // Table header
    print("â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n", .{});
    print("â”‚ Test Name    â”‚ Data Sizeâ”‚  Avg Time â”‚  Min Time â”‚  Max Time â”‚  Throughput  â”‚\n", .{});
    print("â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n", .{});

    for (config.data_sizes) |data_size| {
        // Generate test data
        const test_data = try generateTestData(allocator, data_size, 42);
        defer allocator.free(test_data);

        // Benchmark frequency test
        const freq_result = try benchmarkFrequencyTest(allocator, test_data, config.iterations);
        printBenchmarkResult(freq_result);

        // Benchmark runs test
        const runs_result = try benchmarkRunsTest(allocator, test_data, config.iterations);
        printBenchmarkResult(runs_result);

        // Benchmark DFT test
        const dft_result = try benchmarkDftTest(allocator, test_data, config.iterations);
        printBenchmarkResult(dft_result);

        // Benchmark rank test
        const rank_result = try benchmarkRankTest(allocator, test_data, config.iterations);
        if (rank_result.avg_time_ns > 0) {
            printBenchmarkResult(rank_result);
        }

        if (data_size < config.data_sizes[config.data_sizes.len - 1]) {
            print("â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n", .{});
        }
    }

    print("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n", .{});

    print("\nðŸ“Š Performance Analysis:\n", .{});
    print("- Frequency Test: O(n) complexity, excellent scalability\n", .{});
    print("- Runs Test: O(n) complexity, very fast\n", .{});
    print("- DFT Test: O(n log n) complexity due to FFT optimization\n", .{});
    print("- Rank Test: O(mÂ³) complexity per matrix, depends on data size\n", .{});
    print("\nðŸŽ¯ Optimization Opportunities:\n", .{});
    print("- Use SIMD instructions for bit operations\n", .{});
    print("- Implement parallel processing for large datasets\n", .{});
    print("- Consider memory pool allocation for frequent operations\n", .{});
}

// Test runner entry point
pub fn main() !void {
    var gpa = std.heap.GeneralPurposeAllocator(.{}){};
    defer _ = gpa.deinit();
    const allocator = gpa.allocator();

    try runPerformanceBenchmark(allocator);
}
